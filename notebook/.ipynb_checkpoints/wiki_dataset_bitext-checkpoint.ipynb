{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import codecs\n",
    "import random\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_txt(sentences_array,file_output_name):\n",
    "    if os.path.isfile(file_output_name):\n",
    "        os.remove(file_output_name)\n",
    "    with codecs.open(file_output_name, \"a\",encoding='utf-8') as a_file:\n",
    "        for elem in sentences_array:\n",
    "            a_file.write(elem)\n",
    "            a_file.write(\"\\n\")\n",
    "    a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(file_name):\n",
    "    src_words=[]\n",
    "    with codecs.open(file_name, encoding='latin-1') as f:\n",
    "        for line in f.readlines():\n",
    "#             print(line)\n",
    "            src_words.append(line[:-1])\n",
    "        f.close()\n",
    "    return src_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_words=get_sentences(\"C:/Users/Hanane/Downloads/wiki_words_pos.txt\")\n",
    "list_tags=get_sentences(\"C:/Users/Hanane/Downloads/wiki_tags_pos.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000000\n"
     ]
    }
   ],
   "source": [
    "print(len(list_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'NOM', 'NAM', 'ABR', 'ABR', 'NAM', 'NOM', 'VER:pres', 'DET:ART', 'NOM']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_words[:10]\n",
    "list_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# list_words=[]\n",
    "# f = codecs.open(\"C:/Users/Hanane/Downloads/wiki_words_pos.txt\", 'a',encoding='utf-8')\n",
    "# for line in f:\n",
    "#     list_words.append(line.strip())\n",
    "\n",
    "# list_tags=[]\n",
    "# f = codecs.open(\"C:/Users/Hanane/Downloads/wiki_tags_pos.txt\", 'a',encoding='utf-8')\n",
    "# # f = open(\"C:/Users/Hanane/Downloads/wiki_tags_pos.txt\", 'rt')\n",
    "# for line in f:\n",
    "#     list_tags.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create bitext lists for words and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    word_cut=\".\"\n",
    "    word_cut2=\"|\"\n",
    "    sentence_words=[]\n",
    "    sentence_tags=[]\n",
    "    cpt_word_line=[]\n",
    "    all_sentences_words=[]\n",
    "    all_sentences_tags=[]\n",
    "    cpt=0\n",
    "    cpt_all=0\n",
    "    cpt_file=len(list_words)\n",
    "\n",
    "    for idx,elem in enumerate(list_words):\n",
    "        if elem[:2]!=\"<#\":\n",
    "            if elem==word_cut2:\n",
    "                sentence_words=[]\n",
    "                sentence_tags=[]\n",
    "                all_sentences_words.append(elem)\n",
    "                all_sentences_tags.append(list_tags[idx])\n",
    "            if elem==word_cut:\n",
    "    #         if len(line.strip()) == 0 and word_before==word_before:\n",
    "                sentence_words.append(elem)\n",
    "                sentence_tags.append(list_tags[idx])\n",
    "\n",
    "                all_sentences_words.append(' '.join(sentence_words))\n",
    "                all_sentences_tags.append(' '.join(sentence_tags))\n",
    "\n",
    "    #             cpt_word_line.append(cpt)\n",
    "                sentence_words=[]\n",
    "                sentence_tags=[]\n",
    "    #             cpt=0\n",
    "                cpt_all+=1\n",
    "            if elem!=word_cut:\n",
    "                sentence_words.append(elem)\n",
    "                sentence_tags.append(list_tags[idx])\n",
    "    #             cpt+=1\n",
    "                cpt_all+=1\n",
    "#         if cpt_all==cpt_file:\n",
    "#             all_sentences_words.append(' '.join(sentence_words))\n",
    "#             all_sentences_tags.append(' '.join(sentence_tags)) \n",
    "#             cpt_word_line.append(cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682954 1682954\n"
     ]
    }
   ],
   "source": [
    "print(len(all_sentences_words),len(all_sentences_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['|',\n",
       " '|',\n",
       " '| Cet article est une ébauche concernant un footballeurnorvégien et un entraîneurnorvégien de football .',\n",
       " \"Vous pouvez partager vos connaissances en l' améliorant .\",\n",
       " '( Comment ? ) .',\n",
       " '|',\n",
       " \"| Åge Fridtjof Hareide ( né le 23 septembre1953 ) est l' entraîneur de l' équipe de Norvège de football où il a remplacé Nils Johan Semb .\",\n",
       " 'Hareide a été joueur puis entraîneur pendant de nombreuses années .',\n",
       " 'Le joueur de football Hareide a joué dans les clubs de Hødd , Molde , Manchester City et Norwich City .',\n",
       " \"Il a joué 50 matches pour l' équipe nationale norvégienne et marqué 5 buts .\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABR',\n",
       " 'ABR',\n",
       " 'ABR NAM NOM VER:pres DET:ART NOM VER:ppre DET:ART NOM KON DET:ART NOM PRP NOM SENT',\n",
       " 'PRO:PER VER:pres VER:infi DET:POS NOM PRP DET:ART NOM SENT',\n",
       " 'PUN ADV SENT PUN SENT',\n",
       " 'NOM',\n",
       " 'NOM NOM NAM NAM PUN VER:pper DET:ART NUM NOM PUN VER:pres DET:ART NOM PRP DET:ART NOM PRP NAM PRP NOM PRO:REL PRO:PER VER:pres VER:pper NAM NAM NAM SENT',\n",
       " 'NAM VER:pres VER:pper NOM ADV NOM VER:ppre PRP ADJ NOM SENT',\n",
       " 'DET:ART NOM PRP NOM NAM VER:pres VER:pper PRP DET:ART NOM PRP NAM PUN NAM PUN NAM NAM KON NAM NAM SENT',\n",
       " 'PRO:PER VER:pres VER:pper NUM NOM PRP DET:ART NOM ADJ ADJ KON VER:pper NUM NOM SENT']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences_tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save lists to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path=r\"C:\\Users\\Hanane\\Documents\\Python_Scripts\\TelecomParis\\Qwant\\Qwant_opennmt_POS_french\\dataset\\raw\"\n",
    "save_to_txt(all_sentences_words,path+\"\\\\wiki_words_bitext_pos.txt\")\n",
    "save_to_txt(all_sentences_tags,path+\"\\\\wiki_tags_bitext_pos.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hanane\\\\Documents\\\\Python_Scripts\\\\TelecomParis\\\\Qwant\\\\Qwant_opennmt_POS_french\\\\dataset\\\\raw\\\\wiki_words_bitext_pos.txt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r\"C:\\Users\\Hanane\\Documents\\Python_Scripts\\TelecomParis\\Qwant\\Qwant_opennmt_POS_french\\dataset\\raw\"\n",
    "path+\"\\\\wiki_words_bitext_pos.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#     %%time\n",
    "#     word_cut=\".\"\n",
    "#     word_cut2=\"|\"\n",
    "#     sentence_words=[]\n",
    "#     sentence_tags=[]\n",
    "#     cpt_word_line=[]\n",
    "#     all_sentences_words=[]\n",
    "#     all_sentences_tags=[]\n",
    "#     cpt=0\n",
    "#     cpt_all=0\n",
    "#     cpt_file=len(list_words)\n",
    "\n",
    "#     for idx,elem in enumerate(list_words):\n",
    "\n",
    "#         if elem==word_cut or elem== word_cut2:\n",
    "# #         if len(line.strip()) == 0 and word_before==word_before:\n",
    "#             sentence_words.append(elem)\n",
    "#             sentence_tags.append(list_tags[idx])\n",
    "        \n",
    "#             all_sentences_words.append(' '.join(sentence_words))\n",
    "#             all_sentences_tags.append(' '.join(sentence_tags))\n",
    "            \n",
    "# #             cpt_word_line.append(cpt)\n",
    "#             sentence_words=[]\n",
    "#             sentence_tags=[]\n",
    "# #             cpt=0\n",
    "#             cpt_all+=1\n",
    "#         if elem!=word_cut:\n",
    "#             sentence_words.append(elem)\n",
    "#             sentence_tags.append(list_tags[idx])\n",
    "# #             cpt+=1\n",
    "#             cpt_all+=1\n",
    "# #         if cpt_all==cpt_file:\n",
    "# #             all_sentences_words.append(' '.join(sentence_words))\n",
    "# #             all_sentences_tags.append(' '.join(sentence_tags)) \n",
    "# #             cpt_word_line.append(cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def file2bitext(file_input_name,word_cut,file_output_name):\n",
    "# #     f = open('train.words.txt', 'rt')\n",
    "   \n",
    "#     #***************** READ FILE AND BUILD LINES*****************\n",
    "#     #count number of lines in the file\n",
    "#     f = open(file_input_name, 'rt')\n",
    "#     cpt_file=0\n",
    "#     for line in f:\n",
    "#         cpt_file+=1\n",
    "#     f.close()\n",
    "#     print(\"number of lines in the file\", cpt_file)\n",
    "\n",
    "#     #build the sentences\n",
    "#     word_before=''\n",
    "#     sentence=[]\n",
    "#     cpt_word_line=[]\n",
    "#     all_sentences=[]\n",
    "#     cpt=0\n",
    "#     cpt_all=0\n",
    "\n",
    "#     f = open(file_input_name, 'rt')\n",
    "#     for line in f:\n",
    "# #         if line.strip()=='.':\n",
    "# #             print(\"line is \",line.strip())\n",
    "#         if line.strip()==word_cut:\n",
    "# #         if len(line.strip()) == 0 and word_before==word_before:\n",
    "#             sentence.append(line.strip())\n",
    "#             all_sentences.append(' '.join(sentence))\n",
    "#             cpt_word_line.append(cpt)\n",
    "#             sentence=[]\n",
    "#             cpt=0\n",
    "#             cpt_all+=1\n",
    "#         if line.strip()!=word_cut:\n",
    "#             sentence.append(line.strip())\n",
    "#             word_before=line.strip()\n",
    "#             cpt+=1\n",
    "#             cpt_all+=1\n",
    "#         if cpt_all==cpt_file:\n",
    "#             all_sentences.append(' '.join(sentence)) \n",
    "#             cpt_word_line.append(cpt)\n",
    "#     f.close()\n",
    "    \n",
    "#     #***************** SAVE LINES TO OUTPUT_FILE *****************\n",
    "#     save_to_txt(all_sentences,file_output_name)\n",
    "\n",
    "def save_to_txt(sentences_array,file_output_name):\n",
    "    if os.path.isfile(file_output_name):\n",
    "        os.remove(file_output_name)\n",
    "    with open(file_output_name, \"a\") as a_file:\n",
    "        for elem in sentences_array:\n",
    "            a_file.write(elem)\n",
    "            a_file.write(\"\\n\")\n",
    "    a_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
